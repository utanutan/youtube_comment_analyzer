"""Streamlit YouTube ã‚³ãƒ¡ãƒ³ãƒˆåˆ†æ GUI"""
import os
import pandas as pd
import streamlit as st

from openai_sentiment import OpenAISentimentAnalyzer
from youtube_analyzer import analyze_comments, extract_video_id, fetch_comments


st.set_page_config(page_title="YouTube ã‚³ãƒ¡ãƒ³ãƒˆåˆ†æ", page_icon="ğŸ¥", layout="wide")

st.title("ğŸ¥ YouTube ã‚³ãƒ¡ãƒ³ãƒˆåˆ†æãƒ„ãƒ¼ãƒ«ï¼ˆMVP0ï¼‰")
st.markdown("å‹•ç”»ã®ã‚³ãƒ¡ãƒ³ãƒˆã‚’å–å¾—ã—ã€OpenAI APIã§æ„Ÿæƒ…åˆ†æï¼‹é »å‡ºèªã‚’æŠ½å‡ºã—ã¾ã™ã€‚")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
st.sidebar.header("âš™ï¸ è¨­å®š")

youtube_api_key = st.sidebar.text_input(
    "YouTube API Key",
    type="password",
    value=os.getenv("YT_API_KEY", ""),
    help="YouTube Data API v3ã®APIã‚­ãƒ¼",
)

openai_api_key = st.sidebar.text_input(
    "OpenAI API Key",
    type="password",
    value=os.getenv("OPENAI_API_KEY", ""),
    help="OpenAI APIã‚­ãƒ¼ï¼ˆgpt-4o-miniä½¿ç”¨ï¼‰",
)

model_name = st.sidebar.selectbox(
    "OpenAI ãƒ¢ãƒ‡ãƒ«",
    ["gpt-4o-mini", "gpt-4o", "gpt-3.5-turbo"],
    index=0,
    help="æ„Ÿæƒ…åˆ†æã«ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«",
)

max_comments = st.sidebar.number_input(
    "æœ€å¤§å–å¾—ä»¶æ•°",
    min_value=10,
    max_value=5000,
    value=500,
    step=50,
    help="å–å¾—ã™ã‚‹ã‚³ãƒ¡ãƒ³ãƒˆæ•°ã®ä¸Šé™",
)

include_replies = st.sidebar.checkbox("è¿”ä¿¡ã‚³ãƒ¡ãƒ³ãƒˆã‚‚å–å¾—", value=True)

batch_size = st.sidebar.number_input(
    "æ„Ÿæƒ…åˆ†æãƒãƒƒãƒã‚µã‚¤ã‚º",
    min_value=5,
    max_value=50,
    value=20,
    step=5,
    help="1å›ã®APIå‘¼ã³å‡ºã—ã§åˆ†æã™ã‚‹ã‚³ãƒ¡ãƒ³ãƒˆæ•°",
)

# ãƒ¡ã‚¤ãƒ³å…¥åŠ›
video_url = st.text_input(
    "YouTube å‹•ç”» URL ã¾ãŸã¯ Video ID",
    placeholder="https://www.youtube.com/watch?v=XXXXXXXXXXX",
)

analyze_button = st.button("ğŸ” åˆ†æé–‹å§‹", type="primary", use_container_width=True)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹åˆæœŸåŒ–
if "analysis_result" not in st.session_state:
    st.session_state.analysis_result = None

if analyze_button:
    if not video_url:
        st.error("å‹•ç”»URLã¾ãŸã¯Video IDã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    elif not youtube_api_key:
        st.error("YouTube API Keyã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    elif not openai_api_key:
        st.error("OpenAI API Keyã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    else:
        try:
            # Video IDæŠ½å‡º
            video_id = extract_video_id(video_url)
            st.info(f"Video ID: `{video_id}`")
            
            # ã‚³ãƒ¡ãƒ³ãƒˆå–å¾—
            with st.spinner("ã‚³ãƒ¡ãƒ³ãƒˆå–å¾—ä¸­..."):
                progress_placeholder = st.empty()
                
                def progress_cb(msg):
                    progress_placeholder.text(msg)
                
                comments = fetch_comments(
                    api_key=youtube_api_key,
                    video_id=video_id,
                    max_comments=max_comments,
                    include_replies=include_replies,
                    progress_callback=progress_cb,
                )
                progress_placeholder.empty()
            
            st.success(f"âœ… {len(comments)} ä»¶ã®ã‚³ãƒ¡ãƒ³ãƒˆã‚’å–å¾—ã—ã¾ã—ãŸã€‚")
            
            # æ„Ÿæƒ…åˆ†æ
            with st.spinner("OpenAI APIã§æ„Ÿæƒ…åˆ†æä¸­..."):
                analyzer = OpenAISentimentAnalyzer(
                    api_key=openai_api_key, model=model_name, batch_size=batch_size
                )
                
                sentiment_progress = st.empty()
                
                def sentiment_cb(msg):
                    sentiment_progress.text(msg)
                
                texts = [c.get("textOriginal", "") for c in comments]
                sentiments = analyzer.analyze_batch(texts, progress_callback=sentiment_cb)
                sentiment_progress.empty()
                
                # æ„Ÿæƒ…çµæœã‚’çµ±åˆ
                def sentiment_analyzer_func(text):
                    # ãƒãƒƒãƒçµæœã‹ã‚‰æ¤œç´¢ï¼ˆç°¡æ˜“å®Ÿè£…ï¼‰
                    idx = texts.index(text) if text in texts else 0
                    return sentiments[idx] if idx < len(sentiments) else {"label": "neutral", "score": 0.0, "reason": ""}
                
                analysis = analyze_comments(comments, sentiment_analyzer_func)
            
            st.success("âœ… æ„Ÿæƒ…åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
            st.session_state.analysis_result = analysis
        
        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")

# çµæœè¡¨ç¤º
if st.session_state.analysis_result:
    result = st.session_state.analysis_result
    summary = result["summary"]
    comments_data = result["comments"]
    
    st.divider()
    st.header("ğŸ“Š åˆ†æçµæœ")
    
    # ã‚µãƒãƒªæŒ‡æ¨™
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ç·ã‚³ãƒ¡ãƒ³ãƒˆæ•°", summary["totalComments"])
    with col2:
        st.metric("ãƒã‚¸ãƒ†ã‚£ãƒ–", summary["sentimentDist"]["positive"])
    with col3:
        st.metric("ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«", summary["sentimentDist"]["neutral"])
    with col4:
        st.metric("ãƒã‚¬ãƒ†ã‚£ãƒ–", summary["sentimentDist"]["negative"])
    
    # æ„Ÿæƒ…åˆ†å¸ƒå††ã‚°ãƒ©ãƒ•
    st.subheader("æ„Ÿæƒ…åˆ†å¸ƒ")
    sentiment_df = pd.DataFrame(
        {
            "æ„Ÿæƒ…": ["ãƒã‚¸ãƒ†ã‚£ãƒ–", "ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«", "ãƒã‚¬ãƒ†ã‚£ãƒ–"],
            "ä»¶æ•°": [
                summary["sentimentDist"]["positive"],
                summary["sentimentDist"]["neutral"],
                summary["sentimentDist"]["negative"],
            ],
        }
    )
    st.bar_chart(sentiment_df.set_index("æ„Ÿæƒ…"))
    
    # é »å‡ºãƒˆãƒ¼ã‚¯ãƒ³
    st.subheader("é »å‡ºã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆTop 20ï¼‰")
    top_tokens = summary["topTokens"][:20]
    token_df = pd.DataFrame(top_tokens, columns=["ãƒˆãƒ¼ã‚¯ãƒ³", "å‡ºç¾å›æ•°"])
    st.dataframe(token_df, use_container_width=True)
    
    # ã‚³ãƒ¡ãƒ³ãƒˆä¸€è¦§
    st.subheader("ã‚³ãƒ¡ãƒ³ãƒˆè©³ç´°")
    comments_df = pd.DataFrame(comments_data)
    display_cols = [
        "authorDisplayName",
        "textClean",
        "sentimentLabel",
        "sentimentScore",
        "sentimentReason",
        "likeCount",
        "publishedAt",
    ]
    available_cols = [c for c in display_cols if c in comments_df.columns]
    st.dataframe(
        comments_df[available_cols].rename(
            columns={
                "authorDisplayName": "è‘—è€…",
                "textClean": "ã‚³ãƒ¡ãƒ³ãƒˆ",
                "sentimentLabel": "æ„Ÿæƒ…",
                "sentimentScore": "ã‚¹ã‚³ã‚¢",
                "sentimentReason": "ç†ç”±",
                "likeCount": "ã„ã„ã­",
                "publishedAt": "æŠ•ç¨¿æ—¥æ™‚",
            }
        ),
        use_container_width=True,
        height=400,
    )
    
    # CSV ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    st.subheader("ğŸ“¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
    csv = comments_df[available_cols].to_csv(index=False, encoding="utf-8-sig")
    st.download_button(
        label="ã‚³ãƒ¡ãƒ³ãƒˆ CSV ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=csv,
        file_name="youtube_comments_analysis.csv",
        mime="text/csv",
    )

